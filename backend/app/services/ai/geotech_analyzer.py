"""
Expert AI system for geotechnical audit.
Coordinates document processing, RAG with standards, and engineering risk assessment.

Quick Wins applied:
- temperature=0.2 for deterministic technical output
- Full RAG across all 8 standards (not just Ð“ÐžÐ¡Ð¢ 25100)
- Smart confidence score based on field completeness
- Improved prompts with role correction and structured output
"""
import json
import logging
from typing import Dict, Any, List, Tuple
from openai import AsyncOpenAI
from app.core.config import settings
from app.schemas.copilot import ParsedSpecSchema
from app.services.ai.document_processor import DocumentProcessor

logger = logging.getLogger(__name__)

# â”€â”€ Constants â”€â”€
AI_MODEL = "gpt-4o"
AI_MODEL_CHEAP = "gpt-4o-mini"
AI_TEMPERATURE = 0.2  # Low temperature for deterministic technical extraction


class GeotechAnalyzer:
    """
    Expert system for geotechnical audit.
    Pipeline: Pre-validate â†’ Extract â†’ RAG Risk Assessment â†’ Summary.
    """

    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.PROXY_API_KEY,
            base_url=settings.PROXY_API_BASE_URL,
        )
        self.standards_path = "app/data/standards/geotech_standards.json"
        try:
            with open(self.standards_path, "r", encoding="utf-8") as f:
                self.standards = json.load(f)
        except Exception:
            self.standards = {}

        # Heuristic keywords for quick validation
        self.geotech_keywords = [
            "ÑˆÐ¿ÑƒÐ½Ñ‚", "ÑÐ²Ð°Ð¸", "ÑÐ²Ð°Ñ", "Ð³Ñ€ÑƒÐ½Ñ‚", "Ð³ÐµÐ¾Ð»Ð¾Ð³Ð¸Ñ", "ÐºÐ¾Ñ‚Ð»Ð¾Ð²Ð°Ð½", "Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚",
            "Ð±ÑƒÑ€ÐµÐ½Ð¸Ðµ", "Ð²Ð´Ð°Ð²Ð»Ð¸Ð²Ð°Ð½Ð¸Ðµ", "ÑÑ‚Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ", "Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ",
            "ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð²Ð¾Ð´", "ÑÐºÐ²Ð°Ð¶Ð¸Ð½Ð°", "Ñ€Ð°Ð·Ñ€ÐµÐ·", "Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ", "Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ",
            "Ð½ÐµÑÑƒÑ‰Ð°Ñ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÑŒ", "Ð¾ÑÐ°Ð´ÐºÐ°", "Ð´ÐµÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ", "Ð¸ÑÐ¿Ñ‹Ñ‚Ð°Ð½Ð¸Ðµ",
        ]

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Public API
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def analyze_project(self, processed_doc: Dict[str, Any]) -> Dict[str, Any]:
        """Main entry point for professional audit."""
        full_text = processed_doc.get("full_text", "")
        sections = processed_doc.get("sections", {})

        # 0. Pre-validation
        is_valid, reason = await self._pre_validate_document(full_text)
        if not is_valid:
            raise ValueError(f"Not a geotechnical document: {reason}")

        # 1. Extract technical parameters
        technical_data = await self._extract_technical_parameters(full_text)

        # 2. Build RAG context from ALL standards
        rag_context = self._build_rag_context(technical_data, full_text)

        # 3. Risk assessment with full standards context
        risks = await self._assess_engineering_risks(technical_data, full_text, rag_context)

        # 4. Expert summary
        summary = await self._generate_professional_summary(
            technical_data, risks, sections, rag_context
        )

        # 5. Smart confidence
        confidence = self._compute_confidence(technical_data, full_text)

        return {
            "parsed_data": technical_data,
            "risks": risks,
            "technical_summary": summary,
            "confidence_score": confidence,
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 1: Technical Parameter Extraction
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _extract_technical_parameters(self, text: str) -> ParsedSpecSchema:
        response = await self.client.chat.completions.create(
            model=AI_MODEL,
            temperature=AI_TEMPERATURE,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Ð¢Ñ‹ â€” ÑÑ‚Ð°Ñ€ÑˆÐ¸Ð¹ Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€-Ð³ÐµÐ¾Ñ‚ÐµÑ…Ð½Ð¸Ðº Ñ 20+ Ð»ÐµÑ‚Ð½Ð¸Ð¼ Ð¾Ð¿Ñ‹Ñ‚Ð¾Ð¼ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ "
                        "Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð¸ Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð¾Ð². Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð¢ÐžÐ§ÐÐž Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ "
                        "Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¸Ð· Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð½Ð¾Ð¹/ÑÐ¼ÐµÑ‚Ð½Ð¾Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸.\n\n"
                        "Ð’ÐµÑ€Ð½Ð¸ ÑÑ‚Ñ€Ð¾Ð³Ð¾ JSON ÑÐ¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼Ð¸ Ð¿Ð¾Ð»ÑÐ¼Ð¸:\n"
                        "- work_type (str): Ð¢Ð¸Ð¿ Ñ€Ð°Ð±Ð¾Ñ‚\n"
                        "- volume (float|null): ÐžÐ±ÑŠÐµÐ¼ Ñ€Ð°Ð±Ð¾Ñ‚ (Ñ‡Ð¸ÑÐ»Ð¾, Ð±ÐµÐ· ÐµÐ´Ð¸Ð½Ð¸Ñ†)\n"
                        "- soil_type (str|null): Ð¢Ð¸Ð¿ Ð³Ñ€ÑƒÐ½Ñ‚Ð°\n"
                        "- required_profile (str|null): ÐœÐ°Ñ€ÐºÐ° ÑˆÐ¿ÑƒÐ½Ñ‚Ð°\n"
                        "- depth (float|null): Ð“Ð»ÑƒÐ±Ð¸Ð½Ð° Ð¿Ð¾Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð² Ð¼ÐµÑ‚Ñ€Ð°Ñ… (Ñ‡Ð¸ÑÐ»Ð¾)\n"
                        "- groundwater_level (float|null): Ð£Ð“Ð’ Ð² Ð¼ÐµÑ‚Ñ€Ð°Ñ… (Ñ‡Ð¸ÑÐ»Ð¾)\n"
                        "- special_conditions (list[str]): ÐžÑÐ¾Ð±Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ\n\n"
                        "Ð’ÐÐ–ÐÐž: volume, depth, groundwater_level â€” Ð¢ÐžÐ›Ð¬ÐšÐž Ñ‡Ð¸ÑÐ»Ð° (float), "
                        "Ð±ÐµÐ· ÐµÐ´Ð¸Ð½Ð¸Ñ† Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ñ. Ð•ÑÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð½ÐµÑ‚ â€” ÑÑ‚Ð°Ð²ÑŒ null."
                    ),
                },
                {"role": "user", "content": f"Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¢Ð—:\n\n{text[:15000]}"},
            ],
            response_format={"type": "json_object"},
        )
        data = json.loads(response.choices[0].message.content)
        return ParsedSpecSchema(**data)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 2: RAG â€” Build context from ALL standards
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _build_rag_context(self, data: ParsedSpecSchema, text: str) -> str:
        """
        Build comprehensive normative context by matching ALL relevant standards.
        Uses keyword matching across key_points, rules, and risks.
        """
        context_parts: List[str] = []
        text_lower = text.lower()
        data_str = f"{data.work_type or ''} {data.soil_type or ''} {data.required_profile or ''}".lower()

        for code, standard in self.standards.items():
            title = standard.get("title", "")
            matched_items: List[str] = []

            # Match risks by soil_type and text keywords
            for risk_key, risk_desc in standard.get("risks", {}).items():
                if any(kw in data_str or kw in text_lower for kw in risk_key.lower().split()):
                    matched_items.append(f"  âš  Ð Ð˜Ð¡Ðš ({risk_key}): {risk_desc}")

            # Match rules by text content
            for rule in standard.get("rules", []):
                # Check if rule keywords appear in document
                rule_words = [w for w in rule.lower().split() if len(w) > 4][:3]
                if any(w in text_lower for w in rule_words):
                    matched_items.append(f"  ðŸ“ ÐŸÐ ÐÐ’Ð˜Ð›Ðž: {rule}")

            # Match key_points to provide context
            for point in standard.get("key_points", []):
                point_words = [w for w in point.lower().split() if len(w) > 4][:3]
                if any(w in data_str for w in point_words):
                    matched_items.append(f"  ðŸ“‹ {point}")

            if matched_items:
                header = f"\n### {code} â€” {title}"
                context_parts.append(header + "\n" + "\n".join(matched_items[:6]))

        if not context_parts:
            # Fallback: include all risk sections as general context
            for code, standard in self.standards.items():
                risks = standard.get("risks", {})
                if risks:
                    items = [f"  âš  {k}: {v}" for k, v in list(risks.items())[:2]]
                    context_parts.append(f"\n### {code} â€” {standard.get('title', '')}\n" + "\n".join(items))

        return "\n".join(context_parts) if context_parts else "ÐÐ¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½."

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 3: Risk Assessment with full RAG context
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _assess_engineering_risks(
        self, data: ParsedSpecSchema, text: str, rag_context: str
    ) -> List[Dict[str, str]]:
        response = await self.client.chat.completions.create(
            model=AI_MODEL,
            temperature=AI_TEMPERATURE,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Ð¢Ñ‹ â€” ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ Ð³ÐµÐ¾Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ñ€Ð¸ÑÐºÐ°Ð¼. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€Ð½Ñ‹Ðµ "
                        "Ñ€Ð¸ÑÐºÐ¸ Ð¾Ð±ÑŠÐµÐºÑ‚Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ð¿Ñ€Ð¸Ð²ÐµÐ´Ñ‘Ð½Ð½Ñ‹Ðµ Ð½Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹.\n\n"
                        "Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ð¹:\n"
                        "- Ð¢Ð¸Ð¿ Ð³Ñ€ÑƒÐ½Ñ‚Ð° Ð¸ ÐµÐ³Ð¾ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸\n"
                        "- Ð“Ð»ÑƒÐ±Ð¸Ð½Ñƒ ÐºÐ¾Ñ‚Ð»Ð¾Ð²Ð°Ð½Ð° / Ð¿Ð¾Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ\n"
                        "- Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ Ð³Ñ€ÑƒÐ½Ñ‚Ð¾Ð²Ñ‹Ñ… Ð²Ð¾Ð´\n"
                        "- Ð‘Ð»Ð¸Ð·Ð¾ÑÑ‚ÑŒ Ðº ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ¹ Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐµ\n"
                        "- ÐœÐµÑ‚Ð¾Ð´ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´ÑÑ‚Ð²Ð° Ñ€Ð°Ð±Ð¾Ñ‚ (Ð²Ð¸Ð±Ñ€Ð¾, Ð²Ð´Ð°Ð²Ð»Ð¸Ð²Ð°Ð½Ð¸Ðµ, Ð·Ð°Ð±Ð¸Ð²ÐºÐ°)\n"
                        "- ÐÐ¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸Ð· Ð¿Ñ€Ð¸Ð²ÐµÐ´Ñ‘Ð½Ð½Ñ‹Ñ… Ð“ÐžÐ¡Ð¢ Ð¸ Ð¡ÐŸ\n\n"
                        "Ð’ÐµÑ€Ð½Ð¸ JSON: {\"risks\": [{\"risk\": str, \"impact\": str}, ...]}\n"
                        "ÐšÐ°Ð¶Ð´Ñ‹Ð¹ risk â€” ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð°Ñ Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€Ð½Ð°Ñ ÑƒÐ³Ñ€Ð¾Ð·Ð°.\n"
                        "ÐšÐ°Ð¶Ð´Ñ‹Ð¹ impact â€” ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ (ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹/Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹/Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹) + Ð¿Ð¾ÑÐ»ÐµÐ´ÑÑ‚Ð²Ð¸Ñ."
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"ÐŸÐÐ ÐÐœÐ•Ð¢Ð Ð« ÐžÐ‘ÐªÐ•ÐšÐ¢Ð:\n{data.model_dump_json()}\n\n"
                        f"ÐÐžÐ ÐœÐÐ¢Ð˜Ð’ÐÐ«Ð™ ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢:\n{rag_context}\n\n"
                        f"Ð˜Ð¡Ð¥ÐžÐ”ÐÐ«Ð™ Ð”ÐžÐšÐ£ÐœÐ•ÐÐ¢ (Ð½Ð°Ñ‡Ð°Ð»Ð¾):\n{text[:5000]}"
                    ),
                },
            ],
            response_format={"type": "json_object"},
        )
        result = json.loads(response.choices[0].message.content)
        return result.get("risks", [])

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 4: Expert Summary
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _generate_professional_summary(
        self,
        data: Any,
        risks: List[Any],
        sections: Dict[str, str],
        rag_context: str,
    ) -> str:
        response = await self.client.chat.completions.create(
            model=AI_MODEL,
            temperature=0.35,  # Slightly higher for natural language summary
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Ð¢Ñ‹ â€” Ð³Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€-Ð³ÐµÐ¾Ñ‚ÐµÑ…Ð½Ð¸Ðº, ÑÐ¾ÑÑ‚Ð°Ð²Ð»ÑÑŽÑ‰Ð¸Ð¹ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ð¾Ðµ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ "
                        "Ð´Ð»Ñ B2B ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°. Ð¡Ñ‚Ð¸Ð»ÑŒ: ÑÑ‚Ñ€Ð¾Ð³Ð¸Ð¹, Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹, Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€Ð½Ñ‹Ð¹.\n\n"
                        "Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ (Markdown):\n"
                        "## ÐÐ½Ð°Ð»Ð¸Ð· Ð¾Ð±ÑŠÐµÐºÑ‚Ð°\n"
                        "ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸, Ñ‚Ð¸Ð¿ Ñ€Ð°Ð±Ð¾Ñ‚, ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹.\n\n"
                        "## ÐžÑ†ÐµÐ½ÐºÐ° ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸\n"
                        "Ð“ÐµÐ¾Ð»Ð¾Ð³Ð¸Ñ, Ð³Ð¸Ð´Ñ€Ð¾Ð³ÐµÐ¾Ð»Ð¾Ð³Ð¸Ñ, ÑÑ‚ÐµÑÐ½ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ, ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ.\n\n"
                        "## Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸\n"
                        "ÐœÐµÑ‚Ð¾Ð´ Ñ€Ð°Ð±Ð¾Ñ‚, Ð¾Ð±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ, Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ.\n\n"
                        "## ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ€Ð¸ÑÐºÐ¸\n"
                        "ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÑƒÐ³Ñ€Ð¾Ð·Ñ‹, ÑÑÑ‹Ð»ÐºÐ¸ Ð½Ð° Ð½Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ñ‹.\n\n"
                        "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÑÑ‹Ð»ÐºÐ¸ Ð½Ð° ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð“ÐžÐ¡Ð¢ Ð¸ Ð¡ÐŸ Ð¸Ð· ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°."
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹: {data}\n"
                        f"Ð Ð¸ÑÐºÐ¸: {risks}\n"
                        f"ÐÐ¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n{rag_context}\n"
                        f"Ð“ÐµÐ¾Ð»Ð¾Ð³Ð¸Ñ (ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚): {sections.get('geology', 'ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…')}"
                    ),
                },
            ],
        )
        return response.choices[0].message.content

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 5: Smart Confidence Score
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _compute_confidence(self, data: ParsedSpecSchema, text: str) -> float:
        """
        Compute confidence as weighted sum based on field completeness
        and document quality signals.

        Range: 0.40 (minimum) to 0.98 (full data + rich document)
        """
        score = 0.40  # Base: we always have at least work_type

        # Field completeness (up to +0.40)
        fields = {
            "work_type": (0.05, data.work_type),
            "soil_type": (0.08, data.soil_type),
            "volume": (0.07, data.volume),
            "depth": (0.07, data.depth),
            "required_profile": (0.05, data.required_profile),
            "groundwater_level": (0.05, data.groundwater_level),
            "special_conditions": (0.03, data.special_conditions),
        }
        for weight, value in fields.values():
            if value:
                score += weight

        # Document quality signals (up to +0.18)
        text_len = len(text)
        if text_len > 500:
            score += 0.04
        if text_len > 2000:
            score += 0.04
        if text_len > 5000:
            score += 0.04

        # Keyword density â€” more geotech terms = more relevant document
        text_lower = text.lower()
        keyword_hits = sum(1 for kw in self.geotech_keywords if kw in text_lower)
        if keyword_hits >= 5:
            score += 0.03
        if keyword_hits >= 10:
            score += 0.03

        return round(min(score, 0.98), 2)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Pre-validation
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _pre_validate_document(self, text: str) -> Tuple[bool, str]:
        """Two-phase validation: heuristic keywords + cheap AI check."""
        text_lower = text.lower()
        keyword_hits = sum(1 for kw in self.geotech_keywords if kw in text_lower)

        if keyword_hits >= 3:
            return True, "Heuristic match"

        # Cheap AI validation
        try:
            response = await self.client.chat.completions.create(
                model=AI_MODEL_CHEAP,
                temperature=0.0,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ Ñ‚ÐµÐºÑÑ‚ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð·Ð°Ð´Ð°Ð½Ð¸ÐµÐ¼, "
                            "ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸ÐµÐ¹ Ð¸Ð»Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð¼ Ð² Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ Ð“Ð•ÐžÐ¢Ð•Ð¥ÐÐ˜ÐšÐ˜, "
                            "Ð¡Ð¢Ð ÐžÐ˜Ð¢Ð•Ð›Ð¬Ð¡Ð¢Ð’Ð Ð¤Ð£ÐÐ”ÐÐœÐ•ÐÐ¢ÐžÐ’ Ð¸Ð»Ð¸ Ð¨ÐŸÐ£ÐÐ¢ÐžÐ’Ð«Ð¥ ÐžÐ“Ð ÐÐ–Ð”Ð•ÐÐ˜Ð™.\n"
                            "ÐžÑ‚Ð²ÐµÑ‚ÑŒ JSON: {\"is_geotech\": bool, \"reason\": str}"
                        ),
                    },
                    {"role": "user", "content": f"Ð¢ÐµÐºÑÑ‚ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð° (Ð½Ð°Ñ‡Ð°Ð»Ð¾):\n{text[:2000]}"},
                ],
                response_format={"type": "json_object"},
            )
            result = json.loads(response.choices[0].message.content)
            return result.get("is_geotech", False), result.get("reason", "No reason provided")
        except Exception:
            return keyword_hits >= 1, "Fallback heuristic"


# Singleton
geotech_analyzer = GeotechAnalyzer()
