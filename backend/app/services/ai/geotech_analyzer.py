"""
Expert AI system for geotechnical audit.
Coordinates document processing, RAG with standards, and engineering risk assessment.

Quick Wins applied:
- temperature=0.2 for deterministic technical output
- Full RAG across all 8 standards (not just –ì–û–°–¢ 25100)
- Smart confidence score based on field completeness
- Improved prompts with role correction and structured output
"""
import json
import logging
from typing import Dict, Any, List, Tuple
from openai import AsyncOpenAI
from app.core.config import settings
from app.schemas.copilot import ParsedSpecSchema
from app.services.ai.document_processor import DocumentProcessor

logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ Constants ‚îÄ‚îÄ
AI_MODEL = "gpt-4o"
AI_MODEL_CHEAP = "gpt-4o-mini"
AI_TEMPERATURE = 0.2  # Low temperature for deterministic technical extraction


class GeotechAnalyzer:
    """
    Expert system for geotechnical audit.
    Pipeline: Pre-validate ‚Üí Extract ‚Üí RAG Risk Assessment ‚Üí Summary.
    """

    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.PROXY_API_KEY,
            base_url=settings.PROXY_API_BASE_URL,
        )
        self.standards_path = "app/data/standards/geotech_standards.json"
        try:
            with open(self.standards_path, "r", encoding="utf-8") as f:
                self.standards = json.load(f)
        except Exception:
            self.standards = {}

        # Heuristic keywords for quick validation
        self.geotech_keywords = [
            "—à–ø—É–Ω—Ç", "—Å–≤–∞–∏", "—Å–≤–∞—è", "–≥—Ä—É–Ω—Ç", "–≥–µ–æ–ª–æ–≥–∏—è", "–∫–æ—Ç–ª–æ–≤–∞–Ω", "—Ñ—É–Ω–¥–∞–º–µ–Ω—Ç",
            "–±—É—Ä–µ–Ω–∏–µ", "–≤–¥–∞–≤–ª–∏–≤–∞–Ω–∏–µ", "—Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–µ", "–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ",
            "—É—Ä–æ–≤–µ–Ω—å –≤–æ–¥", "—Å–∫–≤–∞–∂–∏–Ω–∞", "—Ä–∞–∑—Ä–µ–∑", "–ø—Ä–æ—Ñ–∏–ª—å", "–æ—Å–Ω–æ–≤–∞–Ω–∏–µ",
            "–Ω–µ—Å—É—â–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å", "–æ—Å–∞–¥–∫–∞", "–¥–µ—Ñ–æ—Ä–º–∞—Ü–∏—è", "–∏—Å–ø—ã—Ç–∞–Ω–∏–µ",
        ]

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Public API
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    async def analyze_project(self, processed_doc: Dict[str, Any]) -> Dict[str, Any]:
        """Main entry point for professional audit."""
        full_text = processed_doc.get("full_text", "")
        sections = processed_doc.get("sections", {})

        # 0. Pre-validation
        is_valid, reason = await self._pre_validate_document(full_text)
        if not is_valid:
            raise ValueError(f"Not a geotechnical document: {reason}")

        # 1. Extract technical parameters
        technical_data = await self._extract_technical_parameters(full_text)

        # 2. Build RAG context from ALL standards
        rag_context = self._build_rag_context(technical_data, full_text)

        # 3. Risk assessment with full standards context
        risks = await self._assess_engineering_risks(technical_data, full_text, rag_context)

        # 4. Expert summary
        summary = await self._generate_professional_summary(
            technical_data, risks, sections, rag_context
        )

        # 5. Smart confidence
        confidence = self._compute_confidence(technical_data, full_text)

        # 6. Generate Clarifying Questions if needed
        questions = []
        if confidence < 0.8:
            questions = await self._generate_clarifying_questions(technical_data, risks)

        return {
            "parsed_data": technical_data,
            "risks": risks,
            "technical_summary": summary,
            "confidence_score": confidence,
            "clarifying_questions": questions,
        }

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Step 1: Technical Parameter Extraction
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    async def _extract_technical_parameters(self, text: str) -> ParsedSpecSchema:
        response = await self.client.chat.completions.create(
            model=AI_MODEL,
            temperature=AI_TEMPERATURE,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã ‚Äî —Å—Ç–∞—Ä—à–∏–π –∏–Ω–∂–µ–Ω–µ—Ä-–≥–µ–æ—Ç–µ—Ö–Ω–∏–∫ —Å 20+ –ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è "
                        "–æ—Å–Ω–æ–≤–∞–Ω–∏–π –∏ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –¢–û–ß–ù–û –∏–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ "
                        "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–Ω–æ–π/—Å–º–µ—Ç–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.\n\n"
                        "–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏:\n"
                        "- work_type (str): –¢–∏–ø —Ä–∞–±–æ—Ç\n"
                        "- volume (float|null): –û–±—ä–µ–º —Ä–∞–±–æ—Ç (–≤ —Ç–æ–Ω–Ω–∞—Ö –¥–ª—è —à–ø—É–Ω—Ç–∞, –≤ –º–µ—Ç—Ä–∞—Ö –¥–ª—è –±—É—Ä–µ–Ω–∏—è/–≤–¥–∞–≤–ª–∏–≤–∞–Ω–∏—è)\n"
                        "- soil_type (str|null): –¢–∏–ø –≥—Ä—É–Ω—Ç–∞\n"
                        "- required_profile (str|null): –ú–∞—Ä–∫–∞ —à–ø—É–Ω—Ç–∞\n"
                        "- depth (float|null): –ì–ª—É–±–∏–Ω–∞ –ø–æ–≥—Ä—É–∂–µ–Ω–∏—è –≤ –º–µ—Ç—Ä–∞—Ö\n"
                        "- groundwater_level (float|null): –£–ì–í –≤ –º–µ—Ç—Ä–∞—Ö\n"
                        "- special_conditions (list[str]): –û—Å–æ–±—ã–µ —É—Å–ª–æ–≤–∏—è\n"
                        "- complexity_coefficient (float): –û—Ü–µ–Ω–∏ –æ—Ç 1.0 –¥–æ 1.5 (1.5 ‚Äî —Å—Ç–µ—Å–Ω–µ–Ω–Ω–æ—Å—Ç—å, –∑–¥–∞–Ω–∏—è —Ä—è–¥–æ–º, –±–æ–ª–æ—Ç–æ)\n"
                        "- estimated_shifts (int): –û—Ü–µ–Ω–∏ –∫–æ–ª-–≤–æ —Å–º–µ–Ω (–∏—Å—Ö–æ–¥—è –∏–∑ –æ–±—ä–µ–º–∞ –∏ —Ç–∏–ø–∞ —Ä–∞–±–æ—Ç)\n\n"
                        "–í–ê–ñ–ù–û: volume, depth, groundwater_level ‚Äî –¢–û–õ–¨–ö–û —á–∏—Å–ª–∞ (float), "
                        "–±–µ–∑ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è. Complexity_coefficient ‚Äî float, estimated_shifts ‚Äî int. "
                        "–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî —Å—Ç–∞–≤—å null –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è —É—Å–ª–æ–≤–∏–π."
                    ),
                },
                {"role": "user", "content": f"–ò–∑–≤–ª–µ–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¢–ó:\n\n{text[:15000]}"},
            ],
            response_format={"type": "json_object"},
        )
        data = json.loads(response.choices[0].message.content)
        return ParsedSpecSchema(**data)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Step 2: RAG ‚Äî Build context from ALL standards
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def _build_rag_context(self, data: ParsedSpecSchema, text: str) -> str:
        """
        Build comprehensive normative context by matching ALL relevant standards.
        Uses keyword matching across key_points, rules, and risks.
        """
        context_parts: List[str] = []
        text_lower = text.lower()
        data_str = f"{data.work_type or ''} {data.soil_type or ''} {data.required_profile or ''}".lower()

        for code, standard in self.standards.items():
            title = standard.get("title", "")
            matched_items: List[str] = []

            # Match risks by soil_type and text keywords
            for risk_key, risk_desc in standard.get("risks", {}).items():
                if any(kw in data_str or kw in text_lower for kw in risk_key.lower().split()):
                    matched_items.append(f"  ‚ö† –†–ò–°–ö ({risk_key}): {risk_desc}")

            # Match rules by text content
            for rule in standard.get("rules", []):
                # Check if rule keywords appear in document
                rule_words = [w for w in rule.lower().split() if len(w) > 4][:3]
                if any(w in text_lower for w in rule_words):
                    matched_items.append(f"  üìè –ü–†–ê–í–ò–õ–û: {rule}")

            # Match key_points to provide context
            for point in standard.get("key_points", []):
                point_words = [w for w in point.lower().split() if len(w) > 4][:3]
                if any(w in data_str for w in point_words):
                    matched_items.append(f"  üìã {point}")

            if matched_items:
                header = f"\n### {code} ‚Äî {title}"
                context_parts.append(header + "\n" + "\n".join(matched_items[:6]))

        if not context_parts:
            # Fallback: include all risk sections as general context
            for code, standard in self.standards.items():
                risks = standard.get("risks", {})
                if risks:
                    items = [f"  ‚ö† {k}: {v}" for k, v in list(risks.items())[:2]]
                    context_parts.append(f"\n### {code} ‚Äî {standard.get('title', '')}\n" + "\n".join(items))

        return "\n".join(context_parts) if context_parts else "–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω."

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Step 3: Risk Assessment with full RAG context
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    async def _assess_engineering_risks(
        self, data: ParsedSpecSchema, text: str, rag_context: str
    ) -> List[Dict[str, str]]:
        response = await self.client.chat.completions.create(
            model=AI_MODEL,
            temperature=AI_TEMPERATURE,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≥–µ–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Ä–∏—Å–∫–∞–º. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ "
                        "—Ä–∏—Å–∫–∏ –æ–±—ä–µ–∫—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.\n\n"
                        "–£—á–∏—Ç—ã–≤–∞–π:\n"
                        "- –¢–∏–ø –≥—Ä—É–Ω—Ç–∞ –∏ –µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏\n"
                        "- –ì–ª—É–±–∏–Ω—É –∫–æ—Ç–ª–æ–≤–∞–Ω–∞ / –ø–æ–≥—Ä—É–∂–µ–Ω–∏—è\n"
                        "- –£—Ä–æ–≤–µ–Ω—å –≥—Ä—É–Ω—Ç–æ–≤—ã—Ö –≤–æ–¥\n"
                        "- –ë–ª–∏–∑–æ—Å—Ç—å –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞—Å—Ç—Ä–æ–π–∫–µ\n"
                        "- –ú–µ—Ç–æ–¥ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç (–≤–∏–±—Ä–æ, –≤–¥–∞–≤–ª–∏–≤–∞–Ω–∏–µ, –∑–∞–±–∏–≤–∫–∞)\n"
                        "- –ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏–∑ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã—Ö –ì–û–°–¢ –∏ –°–ü\n\n"
                        "–í–µ—Ä–Ω–∏ JSON: {\"risks\": [{\"risk\": str, \"impact\": str}, ...]}\n"
                        "–ö–∞–∂–¥—ã–π risk ‚Äî –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –∏–Ω–∂–µ–Ω–µ—Ä–Ω–∞—è —É–≥—Ä–æ–∑–∞.\n"
                        "–ö–∞–∂–¥—ã–π impact ‚Äî —É—Ä–æ–≤–µ–Ω—å (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π/–í—ã—Å–æ–∫–∏–π/–°—Ä–µ–¥–Ω–∏–π) + –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è."
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"–ü–ê–†–ê–ú–ï–¢–†–´ –û–ë–™–ï–ö–¢–ê:\n{data.model_dump_json()}\n\n"
                        f"–ù–û–†–ú–ê–¢–ò–í–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢:\n{rag_context}\n\n"
                        f"–ò–°–•–û–î–ù–´–ô –î–û–ö–£–ú–ï–ù–¢ (–Ω–∞—á–∞–ª–æ):\n{text[:5000]}"
                    ),
                },
            ],
            response_format={"type": "json_object"},
        )
        result = json.loads(response.choices[0].message.content)
        return result.get("risks", [])

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Step 4: Expert Summary
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    async def _generate_professional_summary(
        self,
        data: Any,
        risks: List[Any],
        sections: Dict[str, str],
        rag_context: str,
    ) -> str:
        response = await self.client.chat.completions.create(
            model=AI_MODEL,
            temperature=0.35,  # Slightly higher for natural language summary
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã ‚Äî –≥–ª–∞–≤–Ω—ã–π –∏–Ω–∂–µ–Ω–µ—Ä-–≥–µ–æ—Ç–µ—Ö–Ω–∏–∫, —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–π —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ "
                        "–¥–ª—è B2B –∫–ª–∏–µ–Ω—Ç–∞. –°—Ç–∏–ª—å: —Å—Ç—Ä–æ–≥–∏–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–π.\n\n"
                        "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–∫–ª—é—á–µ–Ω–∏—è (Markdown):\n"
                        "## –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–∫—Ç–∞\n"
                        "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏, —Ç–∏–ø —Ä–∞–±–æ—Ç, –∫–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.\n\n"
                        "## –û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏\n"
                        "–ì–µ–æ–ª–æ–≥–∏—è, –≥–∏–¥—Ä–æ–≥–µ–æ–ª–æ–≥–∏—è, —Å—Ç–µ—Å–Ω–µ–Ω–Ω–æ—Å—Ç—å, —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —É—Å–ª–æ–≤–∏—è.\n\n"
                        "## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n"
                        "–ú–µ—Ç–æ–¥ —Ä–∞–±–æ—Ç, –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è.\n\n"
                        "## –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏\n"
                        "–û—Å–Ω–æ–≤–Ω—ã–µ —É–≥—Ä–æ–∑—ã, —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤—ã.\n\n"
                        "–ò—Å–ø–æ–ª—å–∑—É–π —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ì–û–°–¢ –∏ –°–ü –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {data}\n"
                        f"–†–∏—Å–∫–∏: {risks}\n"
                        f"–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n{rag_context}\n"
                        f"–ì–µ–æ–ª–æ–≥–∏—è (–∫–æ–Ω—Ç–µ–∫—Å—Ç): {sections.get('geology', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}"
                    ),
                },
            ],
        )
        return response.choices[0].message.content

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Step 5: Smart Confidence Score
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def _compute_confidence(self, data: ParsedSpecSchema, text: str) -> float:
        """
        Compute confidence as weighted sum based on field completeness
        and document quality signals.

        Range: 0.40 (minimum) to 0.98 (full data + rich document)
        """
        score = 0.40  # Base: we always have at least work_type

        # Field completeness (up to +0.40)
        fields = {
            "work_type": (0.05, data.work_type),
            "soil_type": (0.08, data.soil_type),
            "volume": (0.07, data.volume),
            "depth": (0.07, data.depth),
            "required_profile": (0.05, data.required_profile),
            "groundwater_level": (0.05, data.groundwater_level),
            "special_conditions": (0.03, data.special_conditions),
        }
        for weight, value in fields.values():
            if value:
                score += weight

        # Document quality signals (up to +0.18)
        text_len = len(text)
        if text_len > 500:
            score += 0.04
        if text_len > 2000:
            score += 0.04
        if text_len > 5000:
            score += 0.04

        # Keyword density ‚Äî more geotech terms = more relevant document
        text_lower = text.lower()
        keyword_hits = sum(1 for kw in self.geotech_keywords if kw in text_lower)
        if keyword_hits >= 5:
            score += 0.03
        if keyword_hits >= 10:
            score += 0.03

        return round(min(score, 0.98), 2)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Pre-validation
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    async def _pre_validate_document(self, text: str) -> Tuple[bool, str]:
        """Two-phase validation: heuristic keywords + cheap AI check."""
        text_lower = text.lower()
        keyword_hits = sum(1 for kw in self.geotech_keywords if kw in text_lower)

        if keyword_hits >= 3:
            return True, "Heuristic match"

        # Cheap AI validation
        try:
            response = await self.client.chat.completions.create(
                model=AI_MODEL_CHEAP,
                temperature=0.0,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "–û–ø—Ä–µ–¥–µ–ª–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –∑–∞–¥–∞–Ω–∏–µ–º, "
                            "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –∏–ª–∏ –æ—Ç—á–µ—Ç–æ–º –≤ –æ–±–ª–∞—Å—Ç–∏ –ì–ï–û–¢–ï–•–ù–ò–ö–ò, "
                            "–°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–ê –§–£–ù–î–ê–ú–ï–ù–¢–û–í –∏–ª–∏ –®–ü–£–ù–¢–û–í–´–• –û–ì–†–ê–ñ–î–ï–ù–ò–ô.\n"
                            "–û—Ç–≤–µ—Ç—å JSON: {\"is_geotech\": bool, \"reason\": str}"
                        ),
                    },
                    {"role": "user", "content": f"–¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–Ω–∞—á–∞–ª–æ):\n{text[:2000]}"},
                ],
                response_format={"type": "json_object"},
            )
            result = json.loads(response.choices[0].message.content)
            return result.get("is_geotech", False), result.get("reason", "No reason provided")
        except Exception:
            return keyword_hits >= 1, "Fallback heuristic"

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Clarifying Questions
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    async def _generate_clarifying_questions(
        self, data: ParsedSpecSchema, risks: List[Dict[str, str]]
    ) -> List[str]:
        """Generate 3 specific questions if data is missing or vague."""
        try:
            response = await self.client.chat.completions.create(
                model=AI_MODEL,
                temperature=0.3,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –≥–ª–∞–≤–Ω—ã–π –∏–Ω–∂–µ–Ω–µ—Ä. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∑–∞–¥–∞—Ç—å 3 –∫–æ—Ä–æ—Ç–∫–∏—Ö, "
                            "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –∑–∞–∫–∞–∑—á–∏–∫—É, —á—Ç–æ–±—ã —É—Ç–æ—á–Ω–∏—Ç—å –¢–ó.\n"
                            "–°–ø—Ä–∞—à–∏–≤–∞–π —Ç–æ–ª—å–∫–æ –æ —Ç–æ–º, —á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ (–≥—Ä—É–Ω—Ç, –≥–ª—É–±–∏–Ω–∞, –Ω–∞–≥—Ä—É–∑–∫–∏).\n"
                            "–í–µ—Ä–Ω–∏ JSON: {\"questions\": [\"–í–æ–ø—Ä–æ—Å 1?\", \"–í–æ–ø—Ä–æ—Å 2?\", \"–í–æ–ø—Ä–æ—Å 3?\"]}"
                        ),
                    },
                    {
                        "role": "user",
                        "content": (
                            f"–¢–ï–ö–£–©–ò–ï –î–ê–ù–ù–´–ï:\n{data.model_dump_json()}\n"
                            f"–†–ò–°–ö–ò: {json.dumps(risks, ensure_ascii=False)}"
                        ),
                    },
                ],
                response_format={"type": "json_object"},
            )
            result = json.loads(response.choices[0].message.content)
            return result.get("questions", [])[:3]
        except Exception as e:
            logger.warning(f"Failed to generate questions: {e}")
            return []


# Singleton
geotech_analyzer = GeotechAnalyzer()
